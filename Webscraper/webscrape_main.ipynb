{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request as ureq\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \n",
      "\tBallasts - Fluorescent - Platt Electric Supply\n",
      "\n",
      "This category contains only ballasts and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBallasts - HID - Platt Electric Supply\n",
      "\n",
      "This category contains only ballasts and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tDrivers - LED - Platt Electric Supply\n",
      "\n",
      "This category contains only drivers and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Fluorescent - Platt Electric Supply\n",
      "\n",
      ">> \n",
      "\tFluorescent - Circular - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tCircular Lamps - T5 - Platt Electric Supply\n",
      "\n",
      "There are 14 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 14 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCircular Lamps - T6 - Platt Electric Supply\n",
      "\n",
      "There are 3 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 3 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCircular Lamps - T9 - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 0 items on page 2\n",
      "There are 2 page(s) in this descendent\n",
      "There are 15 total items\n",
      "There are 3 sub sub categories within this subcategory\n",
      ">> \n",
      "\tFluorescent - Compact - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tCFL - 2-Pin Base - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 0 items on page 4\n",
      "There are 4 page(s) in this descendent\n",
      "There are 45 total items\n",
      ">>> \n",
      "\tCFL - 4-Pin Base - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 7 items on page 4\n",
      "There are 4 page(s) in this descendent\n",
      "There are 52 total items\n",
      ">>> \n",
      "\tCFL - Square - Platt Electric Supply\n",
      "\n",
      "There are 5 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 5 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCFL - Twist Lock Base - Platt Electric Supply\n",
      "\n",
      "There are 11 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 11 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCFL - Screw-In - Decorative - Platt Electric Supply\n",
      "\n",
      "There are 10 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 10 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCFL - Screw-In - Reflector - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 2 items on page 2\n",
      "There are: 0 items on page 3\n",
      "There are: 0 items on page 4\n",
      "There are: 0 items on page 5\n",
      "There are: 0 items on page 6\n",
      "There are 6 page(s) in this descendent\n",
      "There are 17 total items\n",
      ">>> \n",
      "\tCFL - Screw-In - Traditional - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 0 items on page 2\n",
      "There are: 0 items on page 3\n",
      "There are: 15 items on page 4\n",
      "There are: 0 items on page 5\n",
      "There are: 0 items on page 6\n",
      "There are 6 page(s) in this descendent\n",
      "There are 30 total items\n",
      ">>> \n",
      "\tCFL - Replacement 2-Piece Top - Platt Electric Supply\n",
      "\n",
      "There are 4 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 4 total items\n",
      "There is only one page\n",
      "There are 8 sub sub categories within this subcategory\n",
      ">> \n",
      "\tFluorescent - Tube - T5  - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\t Platt Electric Supply\n",
      "\n",
      "There are no more descendents in this subcategory\n",
      ">> \n",
      "\tFluorescent - Tube - T6  - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\t Platt Electric Supply\n",
      "\n",
      "There are no more descendents in this subcategory\n",
      ">> \n",
      "\tFluorescent - Tube - T8  - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tT8 - Colored - Platt Electric Supply\n",
      "\n",
      "There are 1 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 1 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tT8 - High Output - Platt Electric Supply\n",
      "\n",
      "There are 4 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 4 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tT8 - Long Life - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 8 items on page 3\n",
      "There are 3 page(s) in this descendent\n",
      "There are 38 total items\n",
      ">>> \n",
      "\tT8 - Preheat - Platt Electric Supply\n",
      "\n",
      "There are 4 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 4 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tPhilips Lighting - F32T8/TL950, T8 - Rapid Start, Fluorescent - Tube , Bulbs, Lamps, Ballasts - Platt Electric Supply\n",
      "\n",
      "There are no more descendents in this subcategory\n",
      ">> \n",
      "\tFluorescent - Tube - T10 - Platt Electric Supply\n",
      "\n",
      "There are no more descendents in this subcategory\n",
      ">> \n",
      "\tFluorescent - Tube - T12 - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tGE Lighting - F60T12D, T12 - Standard, Fluorescent - Tube , Bulbs, Lamps, Ballasts - Platt Electric Supply\n",
      "\n",
      "There are no more descendents in this subcategory\n",
      ">> \n",
      "\tFluorescent - U-Bent - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tU-Bent Lamps - T8 - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 15 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tU-Bent Lamps - T12 - Platt Electric Supply\n",
      "\n",
      "There are 3 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 3 total items\n",
      "There is only one page\n",
      "There are 2 sub sub categories within this subcategory\n",
      "There are 8 sub categories within this category\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Halogen - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - HID - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Incandescent - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - LED - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Miniature & Specialty - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tGuards, Changers - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tRecycling - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "There are 14 categories\n",
      "There are 164 total items\n",
      "scraping success!\n"
     ]
    }
   ],
   "source": [
    "# =====|| For Testing ||=====\n",
    "\n",
    "# Define dictionaries to hold soup and path info\n",
    "\n",
    "pathd_cat={}\n",
    "soupd_cat={}\n",
    "beg_path='https://www.platt.com'\n",
    "cat_count=0\n",
    "subcount=0\n",
    "cat_names=[]\n",
    "items=0\n",
    "\n",
    "path='https://www.platt.com/platt-electric-supply/Bulbs-and-Ballasts/search.aspx?SectionID=10'\n",
    "html=ureq.urlopen(path)\n",
    "\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "type(soup)\n",
    "\n",
    "linktable_cat=soup.find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "links_cat=linktable_cat.find_all('a')\n",
    "\n",
    "df=pd.DataFrame() # define dataframe to append all dfsubs to\n",
    "\n",
    "for link in links_cat:\n",
    "       \n",
    "    #print(link.get('href'))\n",
    "    pathd_cat[\"path\"+str(cat_count)]=link.get('href')\n",
    "    tempath=beg_path+pathd_cat[\"path\"+str(cat_count)]\n",
    "    html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "    soupd_cat[\"soup_cat\"+str(cat_count)]=BeautifulSoup(html,'html.parser')\n",
    "    type(soupd_cat[\"soup_cat\"+str(cat_count)])\n",
    "    title=soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "    print(\">\",title)\n",
    "    \n",
    "    pathd_sub={}\n",
    "    soupd_sub={}\n",
    "    subtitles=[]\n",
    "\n",
    "    title_sub = soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "    if \"Ballasts\" not in title_sub:\n",
    "        if \"Drivers\" not in title_sub:\n",
    "            if \"Fluorescent\" in title_sub: # test statement so i don't have to wait ages\n",
    "                linktable_sub=soupd_cat[\"soup_cat\"+str(cat_count)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "                links_sub=linktable_sub.find_all('a')\n",
    "\n",
    "                cat_count_sub=0\n",
    "                dfsub=pd.DataFrame() # define dataframe to append all dfsubsub's to\n",
    "                \n",
    "                for link in links_sub:\n",
    "\n",
    "                    pathd_sub[\"path\"+str(subcount)]=link.get('href')\n",
    "                    tempath=beg_path+pathd_sub[\"path\"+str(subcount)]\n",
    "                    html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                    soupd_sub[\"soup_cat\"+str(subcount)]=BeautifulSoup(html,'html.parser')\n",
    "                    type(soupd_sub[\"soup_cat\"+str(subcount)])\n",
    "\n",
    "                    subtitle=soupd_sub[\"soup_cat\"+str(subcount)].title.get_text()\n",
    "                    if \"\" in subtitle:\n",
    "                        subtitles.append(subtitle)\n",
    "                        print(\">>\",subtitle)\n",
    "\n",
    "                        #subsubcategories\n",
    "                        pathd_subsub={}\n",
    "                        soupd_subsub={}\n",
    "                        subsubcount=0\n",
    "                        subsubtitles=[]\n",
    "\n",
    "                        # if there is no descendent, skip it\n",
    "                        linktable_subsub=soupd_sub[\"soup_cat\"+str(subcount)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "\n",
    "                        try:\n",
    "                            links_subsub=linktable_subsub.find_all('a')\n",
    "                            cat_count_subsub=0\n",
    "                            \n",
    "                            dfsubsub=pd.DataFrame() # define dataframe to append all dfitems to\n",
    "\n",
    "                            for link in links_subsub:\n",
    "\n",
    "                                #print(link.get('href'))\n",
    "                                pathd_subsub[\"path\"+str(subsubcount)]=link.get('href')\n",
    "                                tempath=beg_path+pathd_subsub[\"path\"+str(subsubcount)]\n",
    "                                html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                                soupd_subsub[\"soup_cat\"+str(subsubcount)]=BeautifulSoup(html,'html.parser')\n",
    "                                type(soupd_subsub[\"soup_cat\"+str(subsubcount)])\n",
    "\n",
    "                                subsubtitle=soupd_subsub[\"soup_cat\"+str(subsubcount)].title.get_text()\n",
    "                            \n",
    "                                subsubtitles.append(subsubtitle)\n",
    "                                print(\">>>\",subsubtitle)\n",
    "\n",
    "\n",
    "                                #==================================================================================\n",
    "                                pathd_pagination={}\n",
    "                                soupd_pagination={}\n",
    "                                page_count=1\n",
    "\n",
    "                                pathd_item={}\n",
    "                                soupd_item={}\n",
    "                                item_count=0\n",
    "\n",
    "                                # grab last link in pagination, and create format for page url population\n",
    "                                linktable_pagination=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"searchTopBarPagination\"})\n",
    "                                links_page=linktable_pagination.find_all('a')\n",
    "                                lastlink=linktable_pagination.find('a',{\"class\":\"pg-arrow-last\"})\n",
    "\n",
    "                                # account for pages where there may not be pagination\n",
    "                                try:\n",
    "                                    lastpage=lastlink.get('href')\n",
    "                                    linkformat=beg_path+lastpage\n",
    "                                    last_pagenum=linkformat[-6]\n",
    "\n",
    "                                    # loop through the range of total pages and create urls, starting at 2 because we have already got the first page\n",
    "                                    pagination_urls=list()\n",
    "\n",
    "                                    for i in range(2,int(last_pagenum)+1):\n",
    "\n",
    "                                        # replace page values\n",
    "                                        url_new=linkformat[:int(-6)]+str(i)+linkformat[int(-6)+1:]\n",
    "                                        pagination_urls.append(url_new)\n",
    "                                    lock=0\n",
    "\n",
    "                                except AttributeError:\n",
    "                                    lock=1\n",
    "\n",
    "                                # look at first item page\n",
    "                                linktable_item=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                links_item=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "                                for link in links_item:\n",
    "                                    pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                    tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                    html=ureq.urlopen(tempath)\n",
    "\n",
    "                                    soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                    type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                    itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                    #print(testtitle)\n",
    "                                    item_count+=1\n",
    "                                    items+=1\n",
    "\n",
    "                                print(\"There are\",item_count,\"items on page 1\")\n",
    "                                page1_cnt=item_count\n",
    "\n",
    "                                pgitem_count=0    \n",
    "\n",
    "\n",
    "                                # loop through remaining pages if there are any\n",
    "\n",
    "                                if lock==0:\n",
    "                                    for page in pagination_urls:\n",
    "\n",
    "                                        # get soup for that page\n",
    "                                        html=ureq.urlopen(page)\n",
    "                                        soup=BeautifulSoup(html,'html.parser')\n",
    "                                        type(soup)\n",
    "\n",
    "                                        # grab item page links on pagination page\n",
    "                                        linktable_item=soup.find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                        links=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "\n",
    "                                        pgitem_count=0\n",
    "                                        for link in links:\n",
    "                                            pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                            tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                            html=ureq.urlopen(tempath)\n",
    "\n",
    "                                            soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                            type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                            itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                            #print(itemtitle)\n",
    "                                            item_count+=1\n",
    "                                            pgitem_count+=1\n",
    "                                        page_count+=1\n",
    "\n",
    "                                        print(\"There are:\",pgitem_count,\"items on page\",page_count)\n",
    "                                print(\"There are\",page_count,\"page(s) in this descendent\")\n",
    "                                print(\"There are\",item_count,\"total items\")\n",
    "                                if lock==1:\n",
    "                                    print(\"There is only one page\")\n",
    "\n",
    "                                # ===== DATAFRAME INFORMATION =====\n",
    "                                # With soups for all item pages, iterate through soups to gather information, then create dataframe from them.\n",
    "\n",
    "                                # define dataframe to hold item page info\n",
    "                                dfitem=pd.DataFrame() #********ISSUE: DF REDEFINED EVERY LOOP\n",
    "                                pg_count=0\n",
    "\n",
    "                                # loop through item pages\n",
    "                                for item in soupd_item:\n",
    "                                    itemtitle=soupd_item['soup_cat'+str(pg_count)].title.get_text()\n",
    "                                    #print(itemtitle)\n",
    "\n",
    "                                    # find price box, strips away the tag info and leaves the price. If price isn't listed, skip\n",
    "                                    try:\n",
    "                                        price=soupd_item['soup_cat'+str(pg_count)].find(\"span\",{\"class\":\"ProductPriceOrderBox\"}).get_text(strip=True)\n",
    "                                    except AttributeError:\n",
    "                                        price='NaN'\n",
    "\n",
    "                                    # find description for product\n",
    "                                    description=soupd_item[item].find(\"span\",{\"id\":\"lblDetailDes\"}).get_text(strip=True)\n",
    "\n",
    "                                    prodinfo=[]\n",
    "                                    prodinfo.append(itemtitle)\n",
    "                                    prodinfo.append(description)\n",
    "                                    prodinfo.append(price)\n",
    "                                    df0=pd.DataFrame(prodinfo)\n",
    "                                    df0=df0.transpose()\n",
    "                                    df0.columns=['title','description','price']\n",
    "                                    df0.index=['Value']\n",
    "\n",
    "\n",
    "                                    # find specification table\n",
    "                                    spectable=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable1\"})\n",
    "\n",
    "                                    # loop through spec table and grab all attributes\n",
    "                                    specrows=spectable.find_all('tr')\n",
    "\n",
    "                                    # improved method to grab columns within each row\n",
    "                                    list_rows=[]\n",
    "                                    for row in specrows:\n",
    "                                        cells=row.find_all('td')\n",
    "                                        str_cells=str(cells)\n",
    "                                        clean=re.compile('<.*?>')\n",
    "                                        clean2=(re.sub(clean,'',str_cells))\n",
    "                                        list_rows.append(clean2)\n",
    "                                    type(clean2)\n",
    "\n",
    "                                    # pass array to a dataframe\n",
    "                                    df1=pd.DataFrame(list_rows)\n",
    "\n",
    "                                    # use split function to separate headers from values\n",
    "                                    df1_1=df1[0].str.split(',',n=1,expand=True)\n",
    "                                    df1_1.columns=['Name','Value']\n",
    "\n",
    "                                    # Clean up data\n",
    "                                    df1_1['Name']=df1_1['Name'].str.replace('[','')\n",
    "                                    df1_1['Name']=df1_1['Name'].str.replace(':','')\n",
    "                                    df1_1['Value']=df1_1['Value'].str.replace(']','')\n",
    "\n",
    "                                    # transpose dataframe because the headers are on the rows\n",
    "                                    df1_1=df1_1.transpose()\n",
    "\n",
    "                                    # replace headers with first row and delete first row\n",
    "                                    df1_2=df1_1.rename(columns=df1_1.iloc[0])\n",
    "                                    df1_3=df1_2.drop(df1_2.index[0])\n",
    "\n",
    "                                    # find second specification table\n",
    "                                    spectable2=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable2\"})\n",
    "\n",
    "                                    # loop through spec table and grab all attributes\n",
    "                                    specrows2=spectable2.find_all('tr')\n",
    "\n",
    "                                    # improved method to grab columns within each row\n",
    "                                    list_rows2=[]\n",
    "                                    for row in specrows2:\n",
    "                                        cells=row.find_all('td')\n",
    "                                        str_cells=str(cells)\n",
    "                                        clean=re.compile('<.*?>')\n",
    "                                        clean2=(re.sub(clean,'',str_cells))\n",
    "                                        list_rows2.append(clean2)\n",
    "                                    type(clean2)\n",
    "\n",
    "                                    # pass array to a dataframe\n",
    "                                    df2=pd.DataFrame(list_rows2)\n",
    "\n",
    "                                    # use split function to separate headers from values\n",
    "                                    df2_1=df2[0].str.split(',',n=1,expand=True)\n",
    "                                    df2_1.columns=['Name','Value']\n",
    "\n",
    "                                    # Clean up data\n",
    "                                    df2_1['Name']=df2_1['Name'].str.replace('[','')\n",
    "                                    df2_1['Name']=df2_1['Name'].str.replace(':','')\n",
    "                                    df2_1['Value']=df2_1['Value'].str.replace(']','')\n",
    "\n",
    "                                    # transpose dataframe because the headers are on the rows\n",
    "                                    df2_1=df2_1.transpose()\n",
    "\n",
    "                                    # replace headers with first row and delete first row\n",
    "                                    df2_2=df2_1.rename(columns=df2_1.iloc[0])\n",
    "                                    df2_3=df2_2.drop(df2_2.index[0])\n",
    "\n",
    "                                    # merge this dataframe with the other\n",
    "                                    dfmer=df1_3.join(df2_3,sort=True)\n",
    "                                    dfmer=df0.join(dfmer,sort=True)\n",
    "                                    dfmer['subsubcategory']=subsubtitle\n",
    "                                    dfitem=dfitem.append(dfmer,sort=True)\n",
    "                                    pg_count+=1\n",
    "                                #==================================================================================\n",
    "                                \n",
    "                                # append each subsubcategory data\n",
    "                                dfsubsub['subcategory']=subtitle\n",
    "                                dfsubsub=dfsubsub.append(dfitem,sort=True)\n",
    "                                cat_count_subsub+=1\n",
    "                                subsubcount+=1\n",
    "                            \n",
    "                            print(\"There are\",cat_count_subsub,\"sub sub categories within this subcategory\")  \n",
    "                                        # So every other entry in the dictionary is the html page\n",
    "\n",
    "                        except AttributeError:\n",
    "                            print(\"There are no more descendents in this subcategory\")\n",
    "                \n",
    "                    # append each subcategory to dataframe\n",
    "                    dfsub['category']=title \n",
    "                    dfsub=dfsub.append(dfsubsub,sort=True)\n",
    "\n",
    "                    cat_count_sub+=1\n",
    "                    subcount+=1\n",
    "\n",
    "                print(\"There are\",cat_count_sub,\"sub categories within this category\")  \n",
    "        else:\n",
    "            cat_count+=1\n",
    "            print(\"This category contains only drivers and will be skipped\")\n",
    "    else: \n",
    "        cat_count+=1\n",
    "        print(\"This category contains only ballasts and will be skipped\")\n",
    "    \n",
    "    # append each category dataframe\n",
    "    #df=df.append(dfsub,sort=True)\n",
    "    #df['group']=title    \n",
    "    \n",
    "    cat_count+=1  \n",
    "    print(\"subcategory successfully scraped\")\n",
    "\n",
    "#reindex\n",
    "#dfsub.index=np.arange(1,dfsub.category.count()+1,1) \n",
    "    \n",
    "print(\"There are\",cat_count,\"categories\")  \n",
    "print(\"There are\",items,\"total items\")\n",
    "print(\"scraping success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====|| For Implementation ||=====\n",
    "\n",
    "# Define dictionaries to hold soup and path info\n",
    "\n",
    "pathd_cat={}\n",
    "soupd_cat={}\n",
    "beg_path='https://www.platt.com'\n",
    "cat_count=0\n",
    "subcount=0\n",
    "cat_names=[]\n",
    "items=0\n",
    "\n",
    "# Grab website information\n",
    "path='https://www.platt.com/platt-electric-supply/Bulbs-and-Ballasts/search.aspx?SectionID=10'\n",
    "html=ureq.urlopen(path)\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "type(soup)\n",
    "\n",
    "# Grab links for all subcategories\n",
    "linktable_cat=soup.find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "links_cat=linktable_cat.find_all('a')\n",
    "\n",
    "# loop through all subcategories\n",
    "for link in links_cat:\n",
    "       \n",
    "    # open subcategory    \n",
    "    #print(link.get('href'))\n",
    "    pathd_cat[\"path\"+str(cat_count)]=link.get('href')\n",
    "    tempath=beg_path+pathd_cat[\"path\"+str(cat_count)]\n",
    "    html=ureq.urlopen(tempath)\n",
    "\n",
    "    # Grab subcategory page information and put in dictionary\n",
    "    soupd_cat[\"soup_cat\"+str(cat_count)]=BeautifulSoup(html,'html.parser')\n",
    "    type(soupd_cat[\"soup_cat\"+str(cat_count)])\n",
    "    title=soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "    print(\">\",title)\n",
    "\n",
    "    # define dictionaries and repeat for subcategories\n",
    "    pathd_sub={}\n",
    "    soupd_sub={}\n",
    "    subtitles=[]\n",
    "\n",
    "    title_sub = soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "    if \"Ballasts\" not in title_sub:\n",
    "        if \"Drivers\" not in title_sub:\n",
    "            if \"Fluorescent\" in title_sub: # test statement so i don't have to wait ages\n",
    "                linktable_sub=soupd_cat[\"soup_cat\"+str(cat_count)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "                links_sub=linktable_sub.find_all('a')\n",
    "\n",
    "                cat_count_sub=0\n",
    "                dfsub=pd.DataFrame() # define dataframe to append all dfsubsub's to\n",
    "                \n",
    "                for link in links_sub:\n",
    "\n",
    "                    pathd_sub[\"path\"+str(subcount)]=link.get('href')\n",
    "                    tempath=beg_path+pathd_sub[\"path\"+str(subcount)]\n",
    "                    html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                    soupd_sub[\"soup_cat\"+str(subcount)]=BeautifulSoup(html,'html.parser')\n",
    "                    type(soupd_sub[\"soup_cat\"+str(subcount)])\n",
    "\n",
    "                    subtitle=soupd_sub[\"soup_cat\"+str(subcount)].title.get_text()\n",
    "                    if \"Compact\" in subtitle:\n",
    "                        subtitles.append(subtitle)\n",
    "                        print(\">>\",subtitle)\n",
    "\n",
    "                        # define subsubcategory dictionaries and repeat again\n",
    "                        pathd_subsub={}\n",
    "                        soupd_subsub={}\n",
    "                        subsubcount=0\n",
    "                        subsubtitles=[]\n",
    "\n",
    "                        # if there is no descendent, skip it\n",
    "                        linktable_subsub=soupd_sub[\"soup_cat\"+str(subcount)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "\n",
    "                        try:\n",
    "                            links_subsub=linktable_subsub.find_all('a')\n",
    "                            cat_count_subsub=0\n",
    "                            \n",
    "                            dfsubsub=pd.DataFrame() # define dataframe to append all dfitems to\n",
    "\n",
    "                            for link in links_subsub:\n",
    "\n",
    "                                #print(link.get('href'))\n",
    "                                pathd_subsub[\"path\"+str(subsubcount)]=link.get('href')\n",
    "                                tempath=beg_path+pathd_subsub[\"path\"+str(subsubcount)]\n",
    "                                html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                                soupd_subsub[\"soup_cat\"+str(subsubcount)]=BeautifulSoup(html,'html.parser')\n",
    "                                type(soupd_subsub[\"soup_cat\"+str(subsubcount)])\n",
    "\n",
    "                                subsubtitle=soupd_subsub[\"soup_cat\"+str(subsubcount)].title.get_text()\n",
    "                            \n",
    "                                subsubtitles.append(subsubtitle)\n",
    "                                print(\">>>\",subsubtitle)\n",
    "\n",
    "\n",
    "                                #==================================================================================\n",
    "                                pathd_pagination={}\n",
    "                                soupd_pagination={}\n",
    "                                page_count=1\n",
    "\n",
    "                                pathd_item={}\n",
    "                                soupd_item={}\n",
    "                                item_count=0\n",
    "\n",
    "                                # grab last link in pagination, and create format for page url population\n",
    "                                linktable_pagination=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"searchTopBarPagination\"})\n",
    "                                links_page=linktable_pagination.find_all('a')\n",
    "                                lastlink=linktable_pagination.find('a',{\"class\":\"pg-arrow-last\"})\n",
    "\n",
    "                                # account for pages where there may not be pagination\n",
    "                                try:\n",
    "                                    lastpage=lastlink.get('href')\n",
    "                                    linkformat=beg_path+lastpage\n",
    "                                    last_pagenum=linkformat[-6]\n",
    "\n",
    "                                    # loop through the range of total pages and create urls, starting at 2 because we have already got the first page\n",
    "                                    pagination_urls=list()\n",
    "\n",
    "                                    for i in range(2,int(last_pagenum)+1):\n",
    "\n",
    "                                        # replace page values\n",
    "                                        url_new=linkformat[:int(-6)]+str(i)+linkformat[int(-6)+1:]\n",
    "                                        pagination_urls.append(url_new)\n",
    "                                    lock=0\n",
    "\n",
    "                                except AttributeError:\n",
    "                                    lock=1\n",
    "\n",
    "                                # look at first item page\n",
    "                                linktable_item=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                links_item=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "                                for link in links_item:\n",
    "                                    pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                    tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                    html=ureq.urlopen(tempath)\n",
    "\n",
    "                                    soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                    type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                    itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                    #print(testtitle)\n",
    "                                    item_count+=1\n",
    "                                    items+=1\n",
    "\n",
    "                                print(\"There are\",item_count,\"items on page 1\")\n",
    "                                page1_cnt=item_count\n",
    "\n",
    "                                pgitem_count=0    \n",
    "\n",
    "\n",
    "                                # loop through remaining pages if there are any\n",
    "\n",
    "                                if lock==0:\n",
    "                                    for page in pagination_urls:\n",
    "\n",
    "                                        # get soup for that page\n",
    "                                        html=ureq.urlopen(page)\n",
    "                                        soup=BeautifulSoup(html,'html.parser')\n",
    "                                        type(soup)\n",
    "\n",
    "                                        # grab item page links on pagination page\n",
    "                                        linktable_item=soup.find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                        links=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "\n",
    "                                        pgitem_count=0\n",
    "                                        for link in links:\n",
    "                                            pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                            tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                            html=ureq.urlopen(tempath)\n",
    "\n",
    "                                            soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                            type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                            itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                            #print(itemtitle)\n",
    "                                            item_count+=1\n",
    "                                            pgitem_count+=1\n",
    "                                        page_count+=1\n",
    "\n",
    "                                        print(\"There are:\",pgitem_count,\"items on page\",page_count)\n",
    "                                print(\"There are\",page_count,\"page(s) in this descendent\")\n",
    "                                print(\"There are\",item_count,\"total items\")\n",
    "                                if lock==1:\n",
    "                                    print(\"There is only one page\")\n",
    "\n",
    "                                # ===== DATAFRAME INFORMATION =====\n",
    "                                # With soups for all item pages, iterate through soups to gather information, then create dataframe from them.\n",
    "\n",
    "                                # define dataframe to hold item page info\n",
    "                                dfitem=pd.DataFrame() #********ISSUE: DF REDEFINED EVERY LOOP\n",
    "                                pg_count=0\n",
    "\n",
    "                                # loop through item pages\n",
    "                                for item in soupd_item:\n",
    "                                    itemtitle=soupd_item['soup_cat'+str(pg_count)].title.get_text()\n",
    "                                    #print(itemtitle)\n",
    "\n",
    "                                    # find price box, strips away the tag info and leaves the price. If price isn't listed, skip\n",
    "                                    try:\n",
    "                                        price=soupd_item['soup_cat'+str(pg_count)].find(\"span\",{\"class\":\"ProductPriceOrderBox\"}).get_text(strip=True)\n",
    "                                    except AttributeError:\n",
    "                                        price='NaN'\n",
    "\n",
    "                                    # find description for product\n",
    "                                    description=soupd_item[item].find(\"span\",{\"id\":\"lblDetailDes\"}).get_text(strip=True)\n",
    "\n",
    "                                    prodinfo=[]\n",
    "                                    prodinfo.append(itemtitle)\n",
    "                                    prodinfo.append(description)\n",
    "                                    prodinfo.append(price)\n",
    "                                    df0=pd.DataFrame(prodinfo)\n",
    "                                    df0=df0.transpose()\n",
    "                                    df0.columns=['title','description','price']\n",
    "                                    df0.index=['Value']\n",
    "\n",
    "\n",
    "                                    # find specification table\n",
    "                                    spectable=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable1\"})\n",
    "\n",
    "                                    # loop through spec table and grab all attributes\n",
    "                                    specrows=spectable.find_all('tr')\n",
    "\n",
    "                                    # improved method to grab columns within each row\n",
    "                                    list_rows=[]\n",
    "                                    for row in specrows:\n",
    "                                        cells=row.find_all('td')\n",
    "                                        str_cells=str(cells)\n",
    "                                        clean=re.compile('<.*?>')\n",
    "                                        clean2=(re.sub(clean,'',str_cells))\n",
    "                                        list_rows.append(clean2)\n",
    "                                    type(clean2)\n",
    "\n",
    "                                    # pass array to a dataframe\n",
    "                                    df1=pd.DataFrame(list_rows)\n",
    "\n",
    "                                    # use split function to separate headers from values\n",
    "                                    df1_1=df1[0].str.split(',',n=1,expand=True)\n",
    "                                    df1_1.columns=['Name','Value']\n",
    "\n",
    "                                    # Clean up data\n",
    "                                    df1_1['Name']=df1_1['Name'].str.replace('[','')\n",
    "                                    df1_1['Name']=df1_1['Name'].str.replace(':','')\n",
    "                                    df1_1['Value']=df1_1['Value'].str.replace(']','')\n",
    "\n",
    "                                    # transpose dataframe because the headers are on the rows\n",
    "                                    df1_1=df1_1.transpose()\n",
    "\n",
    "                                    # replace headers with first row and delete first row\n",
    "                                    df1_2=df1_1.rename(columns=df1_1.iloc[0])\n",
    "                                    df1_3=df1_2.drop(df1_2.index[0])\n",
    "\n",
    "                                    # find second specification table\n",
    "                                    spectable2=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable2\"})\n",
    "\n",
    "                                    # loop through spec table and grab all attributes\n",
    "                                    specrows2=spectable2.find_all('tr')\n",
    "\n",
    "                                    # improved method to grab columns within each row\n",
    "                                    list_rows2=[]\n",
    "                                    for row in specrows2:\n",
    "                                        cells=row.find_all('td')\n",
    "                                        str_cells=str(cells)\n",
    "                                        clean=re.compile('<.*?>')\n",
    "                                        clean2=(re.sub(clean,'',str_cells))\n",
    "                                        list_rows2.append(clean2)\n",
    "                                    type(clean2)\n",
    "\n",
    "                                    # pass array to a dataframe\n",
    "                                    df2=pd.DataFrame(list_rows2)\n",
    "\n",
    "                                    # use split function to separate headers from values\n",
    "                                    df2_1=df2[0].str.split(',',n=1,expand=True)\n",
    "                                    df2_1.columns=['Name','Value']\n",
    "\n",
    "                                    # Clean up data\n",
    "                                    df2_1['Name']=df2_1['Name'].str.replace('[','')\n",
    "                                    df2_1['Name']=df2_1['Name'].str.replace(':','')\n",
    "                                    df2_1['Value']=df2_1['Value'].str.replace(']','')\n",
    "\n",
    "                                    # transpose dataframe because the headers are on the rows\n",
    "                                    df2_1=df2_1.transpose()\n",
    "\n",
    "                                    # replace headers with first row and delete first row\n",
    "                                    df2_2=df2_1.rename(columns=df2_1.iloc[0])\n",
    "                                    df2_3=df2_2.drop(df2_2.index[0])\n",
    "\n",
    "                                    # merge this dataframe with the other\n",
    "                                    dfmer=df1_3.join(df2_3,sort=True)\n",
    "                                    dfmer=df0.join(dfmer,sort=True)\n",
    "                                    dfmer['subsubcategory']=subsubtitle\n",
    "                                    dfitem=dfitem.append(dfmer,sort=True)\n",
    "                                    pg_count+=1\n",
    "                                #==================================================================================\n",
    "                                \n",
    "                                # append each subsubcategory data\n",
    "                                dfsubsub=dfsubsub.append(dfitem,sort=True)\n",
    "                                dfsubsub['subcategory']=subtitle\n",
    "                                cat_count_subsub+=1\n",
    "                                subsubcount+=1\n",
    "                            \n",
    "                            print(\"There are\",cat_count_subsub,\"sub sub categories within this subcategory\")  \n",
    "                                        # So every other entry in the dictionary is the html page\n",
    "\n",
    "                        except AttributeError:\n",
    "                            print(\"There are no more descendents in this subcategory\")\n",
    "\n",
    "                print(\"There are\",subsubcount,\"subsub categories within this sub category\")\n",
    "                print(\"success\")\n",
    "                \n",
    "                # append each subsubcategory data\n",
    "                dfsub=dfsub.append(dfsubsub,sort=True)\n",
    "                dfsub['category']=title    \n",
    "                cat_count_sub+=1\n",
    "                subcount+=1\n",
    "\n",
    "                print(\"There are\",cat_count_sub,\"sub categories within this category\")  \n",
    "        else:\n",
    "            cat_count+=1\n",
    "            print(\"This category contains only drivers and will be skipped\")\n",
    "    else: \n",
    "        cat_count+=1\n",
    "        print(\"This category contains only ballasts and will be skipped\")\n",
    "    cat_count+=1  \n",
    "    print(\"subcategory successfully scraped\")\n",
    "\n",
    "    \n",
    "print(\"There are\",cat_count,\"categories\")  \n",
    "print(\"There are\",items,\"total items\")\n",
    "print(\"scraping success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amps</th>\n",
       "      <th>Base</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Category</th>\n",
       "      <th>Color</th>\n",
       "      <th>Color Rendering Index (CRI)</th>\n",
       "      <th>Color Temperature</th>\n",
       "      <th>Country of Origin</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Family / Style</th>\n",
       "      <th>...</th>\n",
       "      <th>Type</th>\n",
       "      <th>UPC</th>\n",
       "      <th>Volts AC</th>\n",
       "      <th>Wattage</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>subsubcategory</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>318</td>\n",
       "      <td>308</td>\n",
       "      <td>107</td>\n",
       "      <td>281</td>\n",
       "      <td>295</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>302</td>\n",
       "      <td>318</td>\n",
       "      <td>157</td>\n",
       "      <td>301</td>\n",
       "      <td>300</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "      <td>288</td>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>271</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>249</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>271</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>23</td>\n",
       "      <td>2-Pin (G13)</td>\n",
       "      <td>F96T8/ADV850/XEW/ALTO 51W</td>\n",
       "      <td></td>\n",
       "      <td>White</td>\n",
       "      <td>82</td>\n",
       "      <td>4100 (Cool White)</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>2.200 in</td>\n",
       "      <td>Pentron</td>\n",
       "      <td>...</td>\n",
       "      <td>Compact Fluorescent, Lamp</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>120</td>\n",
       "      <td>32</td>\n",
       "      <td>\\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...</td>\n",
       "      <td>Fluorescent, High Lumen, Advantage Lamp, 32W, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\r\\n\\tFluorescent - Compact - Platt Electric S...</td>\n",
       "      <td>\\r\\n\\tT8 - Long Life - Platt Electric Supply\\r\\n</td>\n",
       "      <td>\\r\\n\\tPhilips Lighting - F32T8/TL935/ALTO, T8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>38</td>\n",
       "      <td>176</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>23</td>\n",
       "      <td>154</td>\n",
       "      <td>64</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>170</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Amps          Base                         Cat Category    Color  \\\n",
       "count     1           285                         318       308     107   \n",
       "unique    1            33                         271        18       4   \n",
       "top      23   2-Pin (G13)   F96T8/ADV850/XEW/ALTO 51W             White   \n",
       "freq      1            91                           2        90      38   \n",
       "\n",
       "       Color Rendering Index (CRI)   Color Temperature Country of Origin  \\\n",
       "count                          281                 295                52   \n",
       "unique                          13                  14                 3   \n",
       "top                             82   4100 (Cool White)     UNITED STATES   \n",
       "freq                           176                  66                49   \n",
       "\n",
       "         Diameter Family / Style  \\\n",
       "count           7              3   \n",
       "unique          5              2   \n",
       "top      2.200 in        Pentron   \n",
       "freq            2              2   \n",
       "\n",
       "                              ...                          \\\n",
       "count                         ...                           \n",
       "unique                        ...                           \n",
       "top                           ...                           \n",
       "freq                          ...                           \n",
       "\n",
       "                              Type             UPC Volts AC Wattage  \\\n",
       "count                          302             318      157     301   \n",
       "unique                          35             249        4      45   \n",
       "top      Compact Fluorescent, Lamp   Not Available      120      32   \n",
       "freq                            80              23      154      64   \n",
       "\n",
       "                                                 category  \\\n",
       "count                                                 300   \n",
       "unique                                                  1   \n",
       "top     \\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...   \n",
       "freq                                                  300   \n",
       "\n",
       "                                              description price  \\\n",
       "count                                                 318   318   \n",
       "unique                                                271   134   \n",
       "top     Fluorescent, High Lumen, Advantage Lamp, 32W, ...   NaN   \n",
       "freq                                                    2    24   \n",
       "\n",
       "                                              subcategory  \\\n",
       "count                                                 288   \n",
       "unique                                                  4   \n",
       "top     \\r\\n\\tFluorescent - Compact - Platt Electric S...   \n",
       "freq                                                  170   \n",
       "\n",
       "                                          subsubcategory  \\\n",
       "count                                                318   \n",
       "unique                                                17   \n",
       "top     \\r\\n\\tT8 - Long Life - Platt Electric Supply\\r\\n   \n",
       "freq                                                  76   \n",
       "\n",
       "                                                    title  \n",
       "count                                                 318  \n",
       "unique                                                271  \n",
       "top     \\r\\n\\tPhilips Lighting - F32T8/TL935/ALTO, T8 ...  \n",
       "freq                                                    2  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amps</th>\n",
       "      <th>Base</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Category</th>\n",
       "      <th>Color</th>\n",
       "      <th>Color Rendering Index (CRI)</th>\n",
       "      <th>Color Temperature</th>\n",
       "      <th>Country of Origin</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Family / Style</th>\n",
       "      <th>...</th>\n",
       "      <th>Type</th>\n",
       "      <th>UPC</th>\n",
       "      <th>Volts AC</th>\n",
       "      <th>Wattage</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>subsubcategory</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4-Pin (2GX13)</td>\n",
       "      <td>TL5C 40W/835</td>\n",
       "      <td>Circular Lamps - T5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>3500 (Warm White)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Lamp, Fluorescent</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>\\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...</td>\n",
       "      <td>Fluorescent, Circline Lamp, Programmed Start, ...</td>\n",
       "      <td>$24.36</td>\n",
       "      <td>\\r\\n\\tFluorescent - Circular - Platt Electric ...</td>\n",
       "      <td>\\r\\n\\tCircular Lamps - T5 - Platt Electric Sup...</td>\n",
       "      <td>\\r\\n\\tPhilips Lighting - TL5C 40W/835, Circula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4-Pin (2GX13)</td>\n",
       "      <td>TL5C 22W/830</td>\n",
       "      <td>Circular Lamps - T5</td>\n",
       "      <td>Warm White</td>\n",
       "      <td>85</td>\n",
       "      <td>3000 (Warm White)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Lamp, Fluorescent</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>\\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...</td>\n",
       "      <td>Fluorescent, Circline Lamp, Programmed Start, ...</td>\n",
       "      <td>$24.36</td>\n",
       "      <td>\\r\\n\\tFluorescent - Circular - Platt Electric ...</td>\n",
       "      <td>\\r\\n\\tCircular Lamps - T5 - Platt Electric Sup...</td>\n",
       "      <td>\\r\\n\\tPhilips Lighting - TL5C 22W/830, Circula...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Amps            Base             Cat             Category         Color  \\\n",
       "Value  NaN   4-Pin (2GX13)    TL5C 40W/835   Circular Lamps - T5          NaN   \n",
       "Value  NaN   4-Pin (2GX13)   TL5C 22W/830    Circular Lamps - T5   Warm White   \n",
       "\n",
       "      Color Rendering Index (CRI)   Color Temperature Country of Origin  \\\n",
       "Value                          85   3500 (Warm White)               NaN   \n",
       "Value                          85   3000 (Warm White)               NaN   \n",
       "\n",
       "      Diameter Family / Style  \\\n",
       "Value      NaN            NaN   \n",
       "Value      NaN            NaN   \n",
       "\n",
       "                             ...                                        Type  \\\n",
       "Value                        ...                           Lamp, Fluorescent   \n",
       "Value                        ...                           Lamp, Fluorescent   \n",
       "\n",
       "                  UPC Volts AC Wattage  \\\n",
       "Value   Not Available      NaN      40   \n",
       "Value   Not Available      NaN      22   \n",
       "\n",
       "                                                category  \\\n",
       "Value  \\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...   \n",
       "Value  \\r\\n\\tBulbs - Fluorescent - Platt Electric Sup...   \n",
       "\n",
       "                                             description   price  \\\n",
       "Value  Fluorescent, Circline Lamp, Programmed Start, ...  $24.36   \n",
       "Value  Fluorescent, Circline Lamp, Programmed Start, ...  $24.36   \n",
       "\n",
       "                                             subcategory  \\\n",
       "Value  \\r\\n\\tFluorescent - Circular - Platt Electric ...   \n",
       "Value  \\r\\n\\tFluorescent - Circular - Platt Electric ...   \n",
       "\n",
       "                                          subsubcategory  \\\n",
       "Value  \\r\\n\\tCircular Lamps - T5 - Platt Electric Sup...   \n",
       "Value  \\r\\n\\tCircular Lamps - T5 - Platt Electric Sup...   \n",
       "\n",
       "                                                   title  \n",
       "Value  \\r\\n\\tPhilips Lighting - TL5C 40W/835, Circula...  \n",
       "Value  \\r\\n\\tPhilips Lighting - TL5C 22W/830, Circula...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\r\\n\\tCircular Lamps - T5 - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCircular Lamps - T6 - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCircular Lamps - T9 - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - 2-Pin Base - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - 4-Pin Base - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Square - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Twist Lock Base - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Screw-In - Decorative - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Screw-In - Reflector - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Screw-In - Traditional - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tCFL - Replacement 2-Piece Top - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tT8 - Colored - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tT8 - High Output - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tT8 - Long Life - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tT8 - Preheat - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tU-Bent Lamps - T8 - Platt Electric Supply\\r\\n',\n",
       "       '\\r\\n\\tU-Bent Lamps - T12 - Platt Electric Supply\\r\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.subsubcategory.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amps', 'Base', 'Cat', 'Category ', 'Color',\n",
       "       'Color Rendering Index (CRI)', 'Color Temperature', 'Country of Origin',\n",
       "       'Diameter', 'Family / Style', 'Length', 'Lumens', 'Material', 'Mfr',\n",
       "       'Platt Cat', 'Platt Item', 'Shape', 'Type', 'UPC', 'Volts AC',\n",
       "       'Wattage', 'description', 'price', 'subcategory', 'subsubcategory',\n",
       "       'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amps                             2\n",
       "Base                           242\n",
       "Cat                            271\n",
       "Category                       263\n",
       "Color                          109\n",
       "Color Rendering Index (CRI)    232\n",
       "Color Temperature              246\n",
       "Country of Origin                6\n",
       "Diameter                        13\n",
       "Family / Style                   7\n",
       "Length                          41\n",
       "Lumens                         256\n",
       "Material                        33\n",
       "Mfr                              8\n",
       "Platt Cat                      271\n",
       "Platt Item                     271\n",
       "Shape                          235\n",
       "Type                           249\n",
       "UPC                            271\n",
       "Volts AC                       174\n",
       "Wattage                        258\n",
       "description                    271\n",
       "price                          271\n",
       "subcategory                    252\n",
       "subsubcategory                 271\n",
       "title                          271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amps                           object\n",
       "Base                           object\n",
       "Cat                            object\n",
       "Category                       object\n",
       "Color                          object\n",
       "Color Rendering Index (CRI)    object\n",
       "Color Temperature              object\n",
       "Country of Origin              object\n",
       "Diameter                       object\n",
       "Family / Style                 object\n",
       "Length                         object\n",
       "Lumens                         object\n",
       "Material                       object\n",
       "Mfr                            object\n",
       "Platt Cat                      object\n",
       "Platt Item                     object\n",
       "Shape                          object\n",
       "Type                           object\n",
       "UPC                            object\n",
       "Volts AC                       object\n",
       "Wattage                        object\n",
       "description                    object\n",
       "price                          object\n",
       "subcategory                    object\n",
       "subsubcategory                 object\n",
       "title                          object\n",
       "category                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amps', 'Base', 'Cat', 'Category ', 'Color',\n",
       "       'Color Rendering Index (CRI)', 'Color Temperature', 'Country of Origin',\n",
       "       'Diameter', 'Family / Style', 'Length', 'Lumens', 'Material', 'Mfr',\n",
       "       'Platt Cat', 'Platt Item', 'Shape', 'Type', 'UPC', 'Volts AC',\n",
       "       'Wattage', 'description', 'price', 'subcategory', 'subsubcategory',\n",
       "       'title', 'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Based Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### category->subcategory->subsubcategory->item page->pagination->dataframe\n",
    "# define dataframe to hold data\n",
    "\n",
    "df_web=pd.DataFrame()\n",
    "def webscrape(path,dataframe,export=False,savepath='none'):\n",
    "\n",
    "    # Define dictionaries to hold soup and path info\n",
    "    pathd_cat={}\n",
    "    soupd_cat={}\n",
    "    beg_path='https://www.platt.com'\n",
    "    cat_count=0\n",
    "    subcount=0\n",
    "    cat_names=[]\n",
    "\n",
    "    # open website and gather information\n",
    "    html=ureq.urlopen(path)\n",
    "    soup=BeautifulSoup(html,'html.parser')\n",
    "    type(soup)\n",
    "\n",
    "    # gather links\n",
    "    linktable_cat=soup.find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "    links_cat=linktable_cat.find_all('a')\n",
    "\n",
    "    for link in links_cat:\n",
    "\n",
    "        #print(link.get('href'))\n",
    "        pathd_cat[\"path\"+str(cat_count)]=link.get('href')\n",
    "        tempath=beg_path+pathd_cat[\"path\"+str(cat_count)]\n",
    "        html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "        soupd_cat[\"soup_cat\"+str(cat_count)]=BeautifulSoup(html,'html.parser')\n",
    "        type(soupd_cat[\"soup_cat\"+str(cat_count)])\n",
    "        title=soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "        print(\">\",title)\n",
    "\n",
    "        pathd_sub={}\n",
    "        soupd_sub={}\n",
    "        subtitles=[]\n",
    "\n",
    "        title_sub = soupd_cat[\"soup_cat\"+str(cat_count)].title.get_text()\n",
    "        if \"Ballasts\" not in title_sub:\n",
    "            if \"Drivers\" not in title_sub:\n",
    "                if \"Fluorescent\" in title_sub: # test statement so i don't have to wait ages\n",
    "                    linktable_sub=soupd_cat[\"soup_cat\"+str(cat_count)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "                    links_sub=linktable_sub.find_all('a')\n",
    "\n",
    "                    cat_count_sub=0\n",
    "                    dataframe=pd.DataFrame() # define dataframe to append all dfsubsub's to\n",
    "\n",
    "                    for link in links_sub:\n",
    "\n",
    "                        pathd_sub[\"path\"+str(subcount)]=link.get('href')\n",
    "                        tempath=beg_path+pathd_sub[\"path\"+str(subcount)]\n",
    "                        html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                        soupd_sub[\"soup_cat\"+str(subcount)]=BeautifulSoup(html,'html.parser')\n",
    "                        type(soupd_sub[\"soup_cat\"+str(subcount)])\n",
    "\n",
    "                        subtitle=soupd_sub[\"soup_cat\"+str(subcount)].title.get_text()\n",
    "                        if \"Compact\" in subtitle:\n",
    "                            subtitles.append(subtitle)\n",
    "                            print(\">>\",subtitle)\n",
    "\n",
    "                            #subsubcategories\n",
    "                            pathd_subsub={}\n",
    "                            soupd_subsub={}\n",
    "                            subsubcount=0\n",
    "                            subsubtitles=[]\n",
    "\n",
    "                            # if there is no descendent, skip it\n",
    "                            linktable_subsub=soupd_sub[\"soup_cat\"+str(subcount)].find(\"div\",{\"class\":\"SubCategoryList\"})\n",
    "\n",
    "                            try:\n",
    "                                links_subsub=linktable_subsub.find_all('a')\n",
    "                                cat_count_subsub=0\n",
    "\n",
    "                                dfsubsub=pd.DataFrame() # define dataframe to append all dfitems to\n",
    "\n",
    "                                for link in links_subsub:\n",
    "\n",
    "                                    #print(link.get('href'))\n",
    "                                    pathd_subsub[\"path\"+str(subsubcount)]=link.get('href')\n",
    "                                    tempath=beg_path+pathd_subsub[\"path\"+str(subsubcount)]\n",
    "                                    html=ureq.urlopen(tempath)\n",
    "\n",
    "\n",
    "                                    soupd_subsub[\"soup_cat\"+str(subsubcount)]=BeautifulSoup(html,'html.parser')\n",
    "                                    type(soupd_subsub[\"soup_cat\"+str(subsubcount)])\n",
    "\n",
    "                                    subsubtitle=soupd_subsub[\"soup_cat\"+str(subsubcount)].title.get_text()\n",
    "\n",
    "                                    subsubtitles.append(subsubtitle)\n",
    "                                    print(\">>>\",subsubtitle)\n",
    "\n",
    "\n",
    "                                    #==================================================================================\n",
    "                                    pathd_pagination={}\n",
    "                                    soupd_pagination={}\n",
    "                                    page_count=1\n",
    "\n",
    "                                    pathd_item={}\n",
    "                                    soupd_item={}\n",
    "                                    item_count=0\n",
    "\n",
    "                                    # grab last link in pagination, and create format for page url population\n",
    "                                    linktable_pagination=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"searchTopBarPagination\"})\n",
    "                                    links_page=linktable_pagination.find_all('a')\n",
    "                                    lastlink=linktable_pagination.find('a',{\"class\":\"pg-arrow-last\"})\n",
    "\n",
    "                                    # account for pages where there may not be pagination\n",
    "                                    try:\n",
    "                                        lastpage=lastlink.get('href')\n",
    "                                        linkformat=beg_path+lastpage\n",
    "                                        last_pagenum=linkformat[-6]\n",
    "\n",
    "                                        # loop through the range of total pages and create urls, starting at 2 because we have already got the first page\n",
    "                                        pagination_urls=list()\n",
    "\n",
    "                                        for i in range(2,int(last_pagenum)+1):\n",
    "\n",
    "                                            # replace page values\n",
    "                                            url_new=linkformat[:int(-6)]+str(i)+linkformat[int(-6)+1:]\n",
    "                                            pagination_urls.append(url_new)\n",
    "                                        lock=0\n",
    "\n",
    "                                    except AttributeError:\n",
    "                                        lock=1\n",
    "\n",
    "                                    # look at first item page\n",
    "                                    linktable_item=soupd_subsub[\"soup_cat\"+str(subsubcount)].find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                    links_item=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "                                    for link in links_item:\n",
    "                                        pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                        tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                        html=ureq.urlopen(tempath)\n",
    "\n",
    "                                        soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                        type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                        itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                        #print(testtitle)\n",
    "                                        item_count+=1\n",
    "\n",
    "                                    print(\"There are\",item_count,\"items on page 1\")\n",
    "                                    page1_cnt=item_count\n",
    "\n",
    "                                    pgitem_count=0    \n",
    "\n",
    "\n",
    "                                    # loop through remaining pages if there are any\n",
    "\n",
    "                                    if lock==0:\n",
    "                                        for page in pagination_urls:\n",
    "\n",
    "                                            # get soup for that page\n",
    "                                            html=ureq.urlopen(page)\n",
    "                                            soup=BeautifulSoup(html,'html.parser')\n",
    "                                            type(soup)\n",
    "\n",
    "                                            # grab item page links on pagination page\n",
    "                                            linktable_item=soup.find(\"div\",{\"class\":\"SearchProductsTable\"})\n",
    "                                            links=linktable_item.find_all('a',{\"class\":\"productListCatNumLink\"})\n",
    "\n",
    "                                            pgitem_count=0\n",
    "                                            for link in links:\n",
    "                                                pathd_item[\"path\"+str(item_count)]=link.get('href')\n",
    "\n",
    "                                                tempath=beg_path+pathd_item[\"path\"+str(item_count)]\n",
    "                                                html=ureq.urlopen(tempath)\n",
    "\n",
    "                                                soupd_item[\"soup_cat\"+str(item_count)]=BeautifulSoup(html,'html.parser')\n",
    "                                                type(soupd_item[\"soup_cat\"+str(item_count)])\n",
    "                                                itemtitle=soupd_item[\"soup_cat\"+str(item_count)].title.get_text()\n",
    "                                                #print(itemtitle)\n",
    "                                                item_count+=1\n",
    "                                                pgitem_count+=1\n",
    "                                            page_count+=1\n",
    "\n",
    "                                            print(\"There are:\",pgitem_count,\"items on page\",page_count)\n",
    "                                    print(\"There are\",page_count,\"page(s) in this descendent\")\n",
    "                                    print(\"There are\",item_count,\"total items\")\n",
    "                                    if lock==1:\n",
    "                                        print(\"There is only one page\")\n",
    "\n",
    "                                    # ===== DATAFRAME INFORMATION =====\n",
    "                                    # With soups for all item pages, iterate through soups to gather information, then create dataframe from them.\n",
    "\n",
    "                                    # define dataframe to hold item page info\n",
    "                                    dfitem=pd.DataFrame() #********ISSUE: DF REDEFINED EVERY LOOP\n",
    "                                    pg_count=0\n",
    "\n",
    "                                    # loop through item pages\n",
    "                                    for item in soupd_item:\n",
    "                                        itemtitle=soupd_item['soup_cat'+str(pg_count)].title.get_text()\n",
    "                                        #print(itemtitle)\n",
    "\n",
    "                                        # find price box, strips away the tag info and leaves the price. If price isn't listed, skip\n",
    "                                        try:\n",
    "                                            price=soupd_item['soup_cat'+str(pg_count)].find(\"span\",{\"class\":\"ProductPriceOrderBox\"}).get_text(strip=True)\n",
    "                                        except AttributeError:\n",
    "                                            price='NaN'\n",
    "\n",
    "                                        # find description for product\n",
    "                                        description=soupd_item[item].find(\"span\",{\"id\":\"lblDetailDes\"}).get_text(strip=True)\n",
    "\n",
    "                                        prodinfo=[]\n",
    "                                        prodinfo.append(itemtitle)\n",
    "                                        prodinfo.append(description)\n",
    "                                        prodinfo.append(price)\n",
    "                                        df0=pd.DataFrame(prodinfo)\n",
    "                                        df0=df0.transpose()\n",
    "                                        df0.columns=['title','description','price']\n",
    "                                        df0.index=['Value']\n",
    "\n",
    "\n",
    "                                        # find specification table\n",
    "                                        spectable=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable1\"})\n",
    "\n",
    "                                        # loop through spec table and grab all attributes\n",
    "                                        specrows=spectable.find_all('tr')\n",
    "\n",
    "                                        # improved method to grab columns within each row\n",
    "                                        list_rows=[]\n",
    "                                        for row in specrows:\n",
    "                                            cells=row.find_all('td')\n",
    "                                            str_cells=str(cells)\n",
    "                                            clean=re.compile('<.*?>')\n",
    "                                            clean2=(re.sub(clean,'',str_cells))\n",
    "                                            list_rows.append(clean2)\n",
    "                                        type(clean2)\n",
    "\n",
    "                                        # pass array to a dataframe\n",
    "                                        df1=pd.DataFrame(list_rows)\n",
    "\n",
    "                                        # use split function to separate headers from values\n",
    "                                        df1_1=df1[0].str.split(',',n=1,expand=True)\n",
    "                                        df1_1.columns=['Name','Value']\n",
    "\n",
    "                                        # Clean up data\n",
    "                                        df1_1['Name']=df1_1['Name'].str.replace('[','')\n",
    "                                        df1_1['Name']=df1_1['Name'].str.replace(':','')\n",
    "                                        df1_1['Value']=df1_1['Value'].str.replace(']','')\n",
    "\n",
    "                                        # transpose dataframe because the headers are on the rows\n",
    "                                        df1_1=df1_1.transpose()\n",
    "\n",
    "                                        # replace headers with first row and delete first row\n",
    "                                        df1_2=df1_1.rename(columns=df1_1.iloc[0])\n",
    "                                        df1_3=df1_2.drop(df1_2.index[0])\n",
    "\n",
    "                                        # find second specification table\n",
    "                                        spectable2=soupd_item[item].find(\"table\",{\"class\":\"seoSpecTable2\"})\n",
    "\n",
    "                                        # loop through spec table and grab all attributes\n",
    "                                        specrows2=spectable2.find_all('tr')\n",
    "\n",
    "                                        # improved method to grab columns within each row\n",
    "                                        list_rows2=[]\n",
    "                                        for row in specrows2:\n",
    "                                            cells=row.find_all('td')\n",
    "                                            str_cells=str(cells)\n",
    "                                            clean=re.compile('<.*?>')\n",
    "                                            clean2=(re.sub(clean,'',str_cells))\n",
    "                                            list_rows2.append(clean2)\n",
    "                                        type(clean2)\n",
    "\n",
    "                                        # pass array to a dataframe\n",
    "                                        df2=pd.DataFrame(list_rows2)\n",
    "\n",
    "                                        # use split function to separate headers from values\n",
    "                                        df2_1=df2[0].str.split(',',n=1,expand=True)\n",
    "                                        df2_1.columns=['Name','Value']\n",
    "\n",
    "                                        # Clean up data\n",
    "                                        df2_1['Name']=df2_1['Name'].str.replace('[','')\n",
    "                                        df2_1['Name']=df2_1['Name'].str.replace(':','')\n",
    "                                        df2_1['Value']=df2_1['Value'].str.replace(']','')\n",
    "\n",
    "                                        # transpose dataframe because the headers are on the rows\n",
    "                                        df2_1=df2_1.transpose()\n",
    "\n",
    "                                        # replace headers with first row and delete first row\n",
    "                                        df2_2=df2_1.rename(columns=df2_1.iloc[0])\n",
    "                                        df2_3=df2_2.drop(df2_2.index[0])\n",
    "\n",
    "                                        # merge this dataframe with the other\n",
    "                                        dfmer=df1_3.join(df2_3,sort=True)\n",
    "                                        dfmer=df0.join(dfmer,sort=True)\n",
    "                                        dfmer['subsubcategory']=subsubtitle\n",
    "                                        dfitem=dfitem.append(dfmer,sort=True)\n",
    "                                        pg_count+=1\n",
    "                                    #==================================================================================\n",
    "\n",
    "                                    # append each subcategory data\n",
    "                                    dfsubsub=dfsubsub.append(dfitem,sort=True)\n",
    "                                    dfsubsub['subcategory']=subtitle\n",
    "                                    cat_count_subsub+=1\n",
    "                                    subsubcount+=1\n",
    "\n",
    "                                print(\"There are\",cat_count_subsub,\"sub sub categories within this subcategory\")  \n",
    "                                            # So every other entry in the dictionary is the html page\n",
    "\n",
    "                            except AttributeError:\n",
    "                                print(\"There are no more descendents in this subcategory\")\n",
    "\n",
    "                    print(\"There are\",subsubcount,\"subsub categories within this sub category\")\n",
    "                    print(\"success\")\n",
    "\n",
    "                    # append each subsubcategory data\n",
    "                    dataframe=dataframe.append(dfsubsub,sort=True)\n",
    "                    dataframe['category']=title    \n",
    "                    cat_count_sub+=1\n",
    "                    subcount+=1\n",
    "\n",
    "                    print(\"There are\",cat_count_sub,\"sub categories within this category\")  \n",
    "            else:\n",
    "                cat_count+=1\n",
    "                print(\"This category contains only drivers and will be skipped\")\n",
    "        else: \n",
    "            cat_count+=1\n",
    "            print(\"This category contains only ballasts and will be skipped\")\n",
    "        cat_count+=1  \n",
    "        print(\"subcategory successfully scraped\")\n",
    "\n",
    "\n",
    "    print(\"There are\",cat_count,\"categories\")  \n",
    "    print(\"scraping success!\")\n",
    "    \n",
    "    return dataframe\n",
    "    if export == True:\n",
    "        dataframe.to_csv(savepath,encoding='utf-8')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \n",
      "\tBallasts - Fluorescent - Platt Electric Supply\n",
      "\n",
      "This category contains only ballasts and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBallasts - HID - Platt Electric Supply\n",
      "\n",
      "This category contains only ballasts and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tDrivers - LED - Platt Electric Supply\n",
      "\n",
      "This category contains only drivers and will be skipped\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Fluorescent - Platt Electric Supply\n",
      "\n",
      ">> \n",
      "\tFluorescent - Compact - Platt Electric Supply\n",
      "\n",
      ">>> \n",
      "\tCFL - 2-Pin Base - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 15 items on page 4\n",
      "There are 4 page(s) in this descendent\n",
      "There are 60 total items\n",
      ">>> \n",
      "\tCFL - 4-Pin Base - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 15 items on page 4\n",
      "There are 4 page(s) in this descendent\n",
      "There are 60 total items\n",
      ">>> \n",
      "\tCFL - Square - Platt Electric Supply\n",
      "\n",
      "There are 7 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 7 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCFL - Twist Lock Base - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 0 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 0 items on page 4\n",
      "There are 4 page(s) in this descendent\n",
      "There are 30 total items\n",
      ">>> \n",
      "\tCFL - Screw-In - Decorative - Platt Electric Supply\n",
      "\n",
      "There are 10 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 10 total items\n",
      "There is only one page\n",
      ">>> \n",
      "\tCFL - Screw-In - Reflector - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 1 items on page 2\n",
      "There are: 15 items on page 3\n",
      "There are: 15 items on page 4\n",
      "There are: 15 items on page 5\n",
      "There are: 0 items on page 6\n",
      "There are 6 page(s) in this descendent\n",
      "There are 61 total items\n",
      ">>> \n",
      "\tCFL - Screw-In - Traditional - Platt Electric Supply\n",
      "\n",
      "There are 15 items on page 1\n",
      "There are: 15 items on page 2\n",
      "There are: 0 items on page 3\n",
      "There are: 0 items on page 4\n",
      "There are: 15 items on page 5\n",
      "There are: 0 items on page 6\n",
      "There are 6 page(s) in this descendent\n",
      "There are 45 total items\n",
      ">>> \n",
      "\tCFL - Replacement 2-Piece Top - Platt Electric Supply\n",
      "\n",
      "There are 5 items on page 1\n",
      "There are 1 page(s) in this descendent\n",
      "There are 5 total items\n",
      "There is only one page\n",
      "There are 8 sub sub categories within this subcategory\n",
      "There are 8 subsub categories within this sub category\n",
      "success\n",
      "There are 1 sub categories within this category\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Halogen - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - HID - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Incandescent - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - LED - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tBulbs - Miniature & Specialty - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tGuards, Changers - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "> \n",
      "\tRecycling - Platt Electric Supply\n",
      "\n",
      "subcategory successfully scraped\n",
      "There are 14 categories\n",
      "scraping success!\n"
     ]
    }
   ],
   "source": [
    "path='https://www.platt.com/platt-electric-supply/Bulbs-and-Ballasts/search.aspx?SectionID=10' # testing website\n",
    "savepath=r'C:\\Users\\apetersen\\Nexant Market Segmentation\\Exports\\Market Segment Data.csv' # testing savepath\n",
    "dftest=webscrape(path,df_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfsub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-47b22597e391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfsub\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfsub' is not defined"
     ]
    }
   ],
   "source": [
    "dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9da2ca430050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
